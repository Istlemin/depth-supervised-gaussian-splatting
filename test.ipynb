{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Training Cameras\n",
      "Loading Test Cameras\n",
      "Number of points at initialisation :  10000\n"
     ]
    }
   ],
   "source": [
    "from arguments import ModelParams, ArgumentParser\n",
    "from depth_images import calibrate_depth\n",
    "from gaussian_renderer import GaussianModel\n",
    "from scene import Scene\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "parser = ArgumentParser()\n",
    "dataset = ModelParams(parser)\n",
    "dataset.model_path = \"\"\n",
    "dataset.source_path = \"../data/icl-nuim/livingroom1/\"\n",
    "dataset.images = \"images\"\n",
    "dataset.resolution = -1\n",
    "\n",
    "dataset.white_background = False\n",
    "dataset.initialisation = \"random\"\n",
    "dataset.eval=True\n",
    "dataset.num_train_images = 3\n",
    "gaussians = GaussianModel(dataset.sh_degree)\n",
    "scene = Scene(dataset, gaussians,shuffle=False)\n",
    "\n",
    "#calibrate_depth(scene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "# import numpy as np\n",
    "# import torch\n",
    "\n",
    "# img = scene.getTrainCameras()[0].original_image\n",
    "\n",
    "\n",
    "# vertical_kernel = torch.zeros((3,3,1,7)).float()\n",
    "# for i in range(3):\n",
    "#     vertical_kernel[i,i] = torch.tensor([[\n",
    "#         1,6,15,20,15,6,1\n",
    "#     ]]).float()/64\n",
    "# vertical_kernel = vertical_kernel.cuda()\n",
    "# horizontal_kernel = torch.zeros((3,3,7,1)).float()\n",
    "# for i in range(3):\n",
    "#     horizontal_kernel[i,i,:,0] = torch.tensor([\n",
    "#         1,6,15,20,15,6,1\n",
    "#     ]).float()/64\n",
    "# horizontal_kernel = horizontal_kernel.cuda()\n",
    "\n",
    "# img2 = torch.nn.functional.conv2d(img.unsqueeze(0),vertical_kernel,padding='same').squeeze()\n",
    "# img2 = torch.nn.functional.conv2d(img2.unsqueeze(0),horizontal_kernel,padding='same').squeeze()\n",
    "\n",
    "# Image.fromarray((img2.cpu().numpy().transpose((1,2,0))*255).astype(np.uint8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "from utils.graphics_utils import fov2focal, geom_transform_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from depth_images import camera_to_pcd\n",
    "\n",
    "def camera_to_pcd2(camera):\n",
    "    fx = fov2focal(camera.FoVx,camera.image_width)\n",
    "    fy = fov2focal(camera.FoVy,camera.image_height)\n",
    "    intrinics = o3d.camera.PinholeCameraIntrinsic(\n",
    "        camera.image_width,\n",
    "        camera.image_height,\n",
    "        fx,\n",
    "        fy,\n",
    "        camera.image_width/2,\n",
    "        camera.image_height/2,\n",
    "    )\n",
    "    print(fx,fy)\n",
    "\n",
    "    depth_image = 1*camera.depth.numpy()[0].astype(np.float32)\n",
    "    color_image = (camera.original_image.cpu().numpy().transpose((1,2,0))*255).astype(np.uint8)\n",
    "\n",
    "    depth_image_o3d = o3d.geometry.Image(np.ascontiguousarray(depth_image))\n",
    "    color_image_o3d = o3d.geometry.Image(np.ascontiguousarray(color_image))\n",
    "    rgbd_image = o3d.geometry.RGBDImage.create_from_color_and_depth(color_image_o3d,depth_image_o3d,depth_scale=1,depth_trunc=10000,convert_rgb_to_intensity=False)\n",
    "    \n",
    "    mat = camera.world_view_transform.cpu().numpy().T\n",
    "    \n",
    "    pcd = o3d.geometry.PointCloud.create_from_rgbd_image(rgbd_image,intrinics,mat)\n",
    "    pcd.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=2, max_nn=30))\n",
    "    return pcd\n",
    "\n",
    "\n",
    "all_pcds = []\n",
    "for i,camera in enumerate(scene.getTrainCameras()):\n",
    "    points,colors = camera_to_pcd(camera)\n",
    "\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(np.ascontiguousarray(points.cpu()))\n",
    "    pcd.colors = o3d.utility.Vector3dVector(np.ascontiguousarray(colors.cpu()))\n",
    "    all_pcds.append(pcd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.31057999, -0.57301217, -2.12647963],\n",
       "       [ 0.31057999, -0.57301217, -2.12647963],\n",
       "       [ 0.31057999, -0.57301217, -2.12647963],\n",
       "       ...,\n",
       "       [ 1.33596754, -0.13438426, -1.8422215 ],\n",
       "       [ 1.33644664, -0.13438426, -1.84053981],\n",
       "       [ 1.33692563, -0.13438426, -1.83885825]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(all_pcds[0].points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_registration(source, target, radius):\n",
    "    print(\"Apply point-to-plane ICP\")\n",
    "    icp_fine = o3d.registration.registration_colored_icp(\n",
    "        source, target, radius,\n",
    "        np.eye(4),\n",
    "        o3d.registration.ICPConvergenceCriteria(relative_fitness=1e-6,\n",
    "                                                          relative_rmse=1e-6,\n",
    "                                                          max_iteration=50))\n",
    "    \n",
    "    transformation_icp = icp_fine.transformation\n",
    "    information_icp = o3d.registration.get_information_matrix_from_point_clouds(\n",
    "        source, target, radius,\n",
    "        icp_fine.transformation)\n",
    "    return transformation_icp, information_icp\n",
    "\n",
    "\n",
    "def full_registration(pcds, radius):\n",
    "    pose_graph = o3d.registration.PoseGraph()\n",
    "    odometry = np.identity(4)\n",
    "    pose_graph.nodes.append(o3d.registration.PoseGraphNode(odometry))\n",
    "    n_pcds = len(pcds)\n",
    "    for source_id in range(n_pcds):\n",
    "        for target_id in range(source_id + 1, n_pcds):\n",
    "            transformation_icp, information_icp = pairwise_registration(\n",
    "                pcds[source_id], pcds[target_id],radius)\n",
    "            print(\"Build o3d.registration.PoseGraph\")\n",
    "            if source_id == 0:  # odometry case\n",
    "                #odometry = np.dot(transformation_icp, odometry)\n",
    "                pose_graph.nodes.append(\n",
    "                    o3d.registration.PoseGraphNode(np.linalg.inv(transformation_icp)))\n",
    "                pose_graph.edges.append(\n",
    "                    o3d.registration.PoseGraphEdge(source_id,\n",
    "                                                             target_id,\n",
    "                                                             transformation_icp,\n",
    "                                                             information_icp,\n",
    "                                                             uncertain=False))\n",
    "            else:  # loop closure case\n",
    "                pose_graph.edges.append(\n",
    "                    o3d.registration.PoseGraphEdge(source_id,\n",
    "                                                             target_id,\n",
    "                                                             transformation_icp,\n",
    "                                                             information_icp,\n",
    "                                                             uncertain=True))\n",
    "    return pose_graph\n",
    "\n",
    "def register_pointclouds(all_pcds):\n",
    "    print(\"Full registration ...\")\n",
    "    radius = 0.3\n",
    "    #with o3d.utility.VerbosityContextManager(\n",
    "    #        o3d.utility.VerbosityLevel.Debug) as cm:\n",
    "    pose_graph = full_registration(all_pcds,\n",
    "                                    radius)\n",
    "\n",
    "    # print(\"Optimizing PoseGraph ...\")\n",
    "    # option = o3d.registration.GlobalOptimizationOption(\n",
    "    #     max_correspondence_distance=radius,\n",
    "    #     edge_prune_threshold=0.25,\n",
    "    #     reference_node=0)\n",
    "    # # with o3d.utility.VerbosityContextManager(o3d.utility.VerbosityLevel.Debug) as cm:\n",
    "    # o3d.registration.global_optimization(\n",
    "    #     pose_graph, o3d.registration.GlobalOptimizationLevenbergMarquardt(),\n",
    "    #     o3d.registration.GlobalOptimizationConvergenceCriteria(), option)\n",
    "\n",
    "    for point_id in range(len(all_pcds)):\n",
    "        print(pose_graph.nodes[point_id].pose)\n",
    "        all_pcds[point_id].transform(pose_graph.nodes[point_id].pose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manual_reg(source, target):\n",
    "  print(\"Apply point-to-plane ICP\")\n",
    "\n",
    "  threshold = 0.1\n",
    "  trans_init = np.eye(4)\n",
    "  \n",
    "  # result_icp = o3d.registration.registration_icp(\n",
    "  #     source, target, threshold, trans_init,\n",
    "  #     o3d.registration.TransformationEstimationPointToPlane())\n",
    "\n",
    "\n",
    "  result_icp = o3d.registration.registration_colored_icp(\n",
    "          source, target, threshold, trans_init,\n",
    "          o3d.registration.ICPConvergenceCriteria(relative_fitness=1e-6,\n",
    "                                                          relative_rmse=1e-6,\n",
    "                                                          max_iteration=50))\n",
    "  print(result_icp)\n",
    "  print(\"Transformation is:\")\n",
    "  print(result_icp.transformation)\n",
    "\n",
    "  trans = np.linalg.inv(result_icp.transformation)\n",
    "  target.transform(trans)\n",
    "  return trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# register_pointclouds(all_pcds)\n",
    "# save_pcds = all_pcds\n",
    "\n",
    "import copy\n",
    "\n",
    "save_pcds = [copy.deepcopy(all_pcds[i]) for i in range(len(all_pcds))]\n",
    "transformations = [np.eye(4)]\n",
    "ref_pcd = save_pcds[0]\n",
    "\n",
    "# for i in range(1,len(all_pcds)):\n",
    "#     transformations.append(manual_reg(ref_pcd,save_pcds[i]))\n",
    "#     ref_pcd = ref_pcd+save_pcds[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_points = []\n",
    "all_colors = []\n",
    "for i,pcd in enumerate(save_pcds):\n",
    "    points = np.array(pcd.points)\n",
    "    colors = np.array(pcd.colors)\n",
    "    \n",
    "    # colors = np.zeros_like(points)\n",
    "    # colors[:,i%3] = 1.0\n",
    "    # if i>=3:\n",
    "    #     colors[:,(i+1)%3] = 1.0\n",
    "    \n",
    "    all_points.append(points)\n",
    "    all_colors.append(colors)\n",
    "    \n",
    "# all_points.append(np.stack([camera.camera_center.cpu().numpy() for camera in scene.getTrainCameras()]))\n",
    "# all_colors.append(np.array([[1.0,0,0]]*len(scene.getTrainCameras())))\n",
    "    \n",
    "\n",
    "from depth_images import camera_frustrum_points\n",
    "\n",
    "cam_frust_points = camera_frustrum_points(scene.getTrainCameras()[0])\n",
    "\n",
    "all_points.append(cam_frust_points.cpu().numpy())\n",
    "all_colors.append(np.array([[1.0,0,0]]*len(cam_frust_points)))\n",
    "\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(np.concatenate(all_points))\n",
    "pcd.colors = o3d.utility.Vector3dVector(np.concatenate(all_colors))\n",
    "o3d.io.write_point_cloud(\"test.ply\", pcd)\n",
    "#!cp test.ply /mnt/c/Users/fredr/repos/test.ply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0', '2282', '994']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[camera.image_name for camera in scene.getTrainCameras()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0343, 0.0377, 0.0410, 0.0442, 0.0472, 0.0498, 0.0521, 0.0540, 0.0554,\n",
       "        0.0562, 0.0565, 0.0562, 0.0554, 0.0540, 0.0521, 0.0498, 0.0472, 0.0442,\n",
       "        0.0410, 0.0377, 0.0343])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import math\n",
    "\n",
    "def gaussian_kernel_1d(sigma: float, num_sigmas: float = 3.) -> torch.Tensor:\n",
    "    \n",
    "    radius = math.ceil(num_sigmas * sigma)\n",
    "    support = torch.arange(-radius, radius + 1, dtype=torch.float)\n",
    "    kernel = torch.distributions.Normal(loc=0, scale=sigma).log_prob(support).exp_()\n",
    "    # Ensure kernel weights sum to 1, so that image brightness is not altered\n",
    "    return kernel.mul_(1 / kernel.sum())\n",
    "\n",
    "gaussian_kernel_1d(10,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0044, 0.0540, 0.2420, 0.3991, 0.2420, 0.0540, 0.0044])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gaussian_splatting",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
