{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Training Cameras\n",
      "Loading Test Cameras\n",
      "Number of points at initialisation :  10000\n"
     ]
    }
   ],
   "source": [
    "from arguments import ModelParams, ArgumentParser\n",
    "from depth_images import calibrate_depth\n",
    "from gaussian_renderer import GaussianModel\n",
    "from scene import Scene\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "parser = ArgumentParser()\n",
    "dataset = ModelParams(parser)\n",
    "dataset.model_path = \"\"\n",
    "dataset.source_path = \"../data/icl-nuim/livingroom1/\"\n",
    "dataset.images = \"images\"\n",
    "dataset.resolution = -1\n",
    "dataset.white_background = False\n",
    "dataset.initialisation = \"random\"\n",
    "dataset.eval=True\n",
    "dataset.num_train_images = 3\n",
    "gaussians = GaussianModel(dataset.sh_degree)\n",
    "scene = Scene(dataset, gaussians,shuffle=False)\n",
    "\n",
    "#calibrate_depth(scene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "from utils.graphics_utils import fov2focal, geom_transform_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fredrik/anaconda3/envs/gaussian_splatting/lib/python3.7/site-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484801627/work/aten/src/ATen/native/TensorShape.cpp:2894.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "from depth_images import camera_to_pcd\n",
    "\n",
    "def camera_to_pcd2(camera):\n",
    "    fx = fov2focal(camera.FoVx,camera.image_width)\n",
    "    fy = fov2focal(camera.FoVy,camera.image_height)\n",
    "    intrinics = o3d.camera.PinholeCameraIntrinsic(\n",
    "        camera.image_width,\n",
    "        camera.image_height,\n",
    "        fx,\n",
    "        fy,\n",
    "        camera.image_width/2,\n",
    "        camera.image_height/2,\n",
    "    )\n",
    "    print(fx,fy)\n",
    "\n",
    "    depth_image = 1*camera.depth.numpy()[0].astype(np.float32)\n",
    "    color_image = (camera.original_image.cpu().numpy().transpose((1,2,0))*255).astype(np.uint8)\n",
    "\n",
    "    depth_image_o3d = o3d.geometry.Image(np.ascontiguousarray(depth_image))\n",
    "    color_image_o3d = o3d.geometry.Image(np.ascontiguousarray(color_image))\n",
    "    rgbd_image = o3d.geometry.RGBDImage.create_from_color_and_depth(color_image_o3d,depth_image_o3d,depth_scale=1,depth_trunc=10000,convert_rgb_to_intensity=False)\n",
    "    \n",
    "    mat = camera.world_view_transform.cpu().numpy().T\n",
    "    \n",
    "    pcd = o3d.geometry.PointCloud.create_from_rgbd_image(rgbd_image,intrinics,mat)\n",
    "    pcd.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=2, max_nn=30))\n",
    "    return pcd\n",
    "\n",
    "\n",
    "all_pcds = []\n",
    "for i,camera in enumerate(scene.getTrainCameras()):\n",
    "    points,colors = camera_to_pcd(camera)\n",
    "\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(np.ascontiguousarray(points.cpu()))\n",
    "    pcd.colors = o3d.utility.Vector3dVector(np.ascontiguousarray(colors.cpu()))\n",
    "    all_pcds.append(pcd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.31057999, -0.57301217, -2.12647963],\n",
       "       [ 0.31057999, -0.57301217, -2.12647963],\n",
       "       [ 0.31057999, -0.57301217, -2.12647963],\n",
       "       ...,\n",
       "       [ 1.33596754, -0.13438426, -1.8422215 ],\n",
       "       [ 1.33644664, -0.13438426, -1.84053981],\n",
       "       [ 1.33692563, -0.13438426, -1.83885825]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(all_pcds[0].points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_registration(source, target, radius):\n",
    "    print(\"Apply point-to-plane ICP\")\n",
    "    icp_fine = o3d.registration.registration_colored_icp(\n",
    "        source, target, radius,\n",
    "        np.eye(4),\n",
    "        o3d.registration.ICPConvergenceCriteria(relative_fitness=1e-6,\n",
    "                                                          relative_rmse=1e-6,\n",
    "                                                          max_iteration=50))\n",
    "    \n",
    "    transformation_icp = icp_fine.transformation\n",
    "    information_icp = o3d.registration.get_information_matrix_from_point_clouds(\n",
    "        source, target, radius,\n",
    "        icp_fine.transformation)\n",
    "    return transformation_icp, information_icp\n",
    "\n",
    "\n",
    "def full_registration(pcds, radius):\n",
    "    pose_graph = o3d.registration.PoseGraph()\n",
    "    odometry = np.identity(4)\n",
    "    pose_graph.nodes.append(o3d.registration.PoseGraphNode(odometry))\n",
    "    n_pcds = len(pcds)\n",
    "    for source_id in range(n_pcds):\n",
    "        for target_id in range(source_id + 1, n_pcds):\n",
    "            transformation_icp, information_icp = pairwise_registration(\n",
    "                pcds[source_id], pcds[target_id],radius)\n",
    "            print(\"Build o3d.registration.PoseGraph\")\n",
    "            if source_id == 0:  # odometry case\n",
    "                #odometry = np.dot(transformation_icp, odometry)\n",
    "                pose_graph.nodes.append(\n",
    "                    o3d.registration.PoseGraphNode(np.linalg.inv(transformation_icp)))\n",
    "                pose_graph.edges.append(\n",
    "                    o3d.registration.PoseGraphEdge(source_id,\n",
    "                                                             target_id,\n",
    "                                                             transformation_icp,\n",
    "                                                             information_icp,\n",
    "                                                             uncertain=False))\n",
    "            else:  # loop closure case\n",
    "                pose_graph.edges.append(\n",
    "                    o3d.registration.PoseGraphEdge(source_id,\n",
    "                                                             target_id,\n",
    "                                                             transformation_icp,\n",
    "                                                             information_icp,\n",
    "                                                             uncertain=True))\n",
    "    return pose_graph\n",
    "\n",
    "def register_pointclouds(all_pcds):\n",
    "    print(\"Full registration ...\")\n",
    "    radius = 0.3\n",
    "    #with o3d.utility.VerbosityContextManager(\n",
    "    #        o3d.utility.VerbosityLevel.Debug) as cm:\n",
    "    pose_graph = full_registration(all_pcds,\n",
    "                                    radius)\n",
    "\n",
    "    # print(\"Optimizing PoseGraph ...\")\n",
    "    # option = o3d.registration.GlobalOptimizationOption(\n",
    "    #     max_correspondence_distance=radius,\n",
    "    #     edge_prune_threshold=0.25,\n",
    "    #     reference_node=0)\n",
    "    # # with o3d.utility.VerbosityContextManager(o3d.utility.VerbosityLevel.Debug) as cm:\n",
    "    # o3d.registration.global_optimization(\n",
    "    #     pose_graph, o3d.registration.GlobalOptimizationLevenbergMarquardt(),\n",
    "    #     o3d.registration.GlobalOptimizationConvergenceCriteria(), option)\n",
    "\n",
    "    for point_id in range(len(all_pcds)):\n",
    "        print(pose_graph.nodes[point_id].pose)\n",
    "        all_pcds[point_id].transform(pose_graph.nodes[point_id].pose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manual_reg(source, target):\n",
    "  print(\"Apply point-to-plane ICP\")\n",
    "\n",
    "  threshold = 0.1\n",
    "  trans_init = np.eye(4)\n",
    "  \n",
    "  # result_icp = o3d.registration.registration_icp(\n",
    "  #     source, target, threshold, trans_init,\n",
    "  #     o3d.registration.TransformationEstimationPointToPlane())\n",
    "\n",
    "\n",
    "  result_icp = o3d.registration.registration_colored_icp(\n",
    "          source, target, threshold, trans_init,\n",
    "          o3d.registration.ICPConvergenceCriteria(relative_fitness=1e-6,\n",
    "                                                          relative_rmse=1e-6,\n",
    "                                                          max_iteration=50))\n",
    "  print(result_icp)\n",
    "  print(\"Transformation is:\")\n",
    "  print(result_icp.transformation)\n",
    "\n",
    "  trans = np.linalg.inv(result_icp.transformation)\n",
    "  target.transform(trans)\n",
    "  return trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# register_pointclouds(all_pcds)\n",
    "# save_pcds = all_pcds\n",
    "\n",
    "import copy\n",
    "\n",
    "save_pcds = [copy.deepcopy(all_pcds[i]) for i in range(len(all_pcds))]\n",
    "transformations = [np.eye(4)]\n",
    "ref_pcd = save_pcds[0]\n",
    "\n",
    "# for i in range(1,len(all_pcds)):\n",
    "#     transformations.append(manual_reg(ref_pcd,save_pcds[i]))\n",
    "#     ref_pcd = ref_pcd+save_pcds[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_points = []\n",
    "all_colors = []\n",
    "for i,pcd in enumerate(save_pcds):\n",
    "    points = np.array(pcd.points)\n",
    "    colors = np.array(pcd.colors)\n",
    "    \n",
    "    # colors = np.zeros_like(points)\n",
    "    # colors[:,i%3] = 1.0\n",
    "    # if i>=3:\n",
    "    #     colors[:,(i+1)%3] = 1.0\n",
    "    \n",
    "    all_points.append(points)\n",
    "    all_colors.append(colors)\n",
    "    \n",
    "# all_points.append(np.stack([camera.camera_center.cpu().numpy() for camera in scene.getTrainCameras()]))\n",
    "# all_colors.append(np.array([[1.0,0,0]]*len(scene.getTrainCameras())))\n",
    "\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(np.concatenate(all_points))\n",
    "pcd.colors = o3d.utility.Vector3dVector(np.concatenate(all_colors))\n",
    "o3d.io.write_point_cloud(\"test.ply\", pcd)\n",
    "#!cp test.ply /mnt/c/Users/fredr/repos/test.ply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[camera.image_name for camera in scene.getTrainCameras()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gaussian_splatting",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
